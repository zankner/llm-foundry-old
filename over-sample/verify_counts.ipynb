{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zackankner/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from streaming import StreamingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_base = \"s3://data-force-one-datasets/mpt-base-data/gpt-neox-20b-seqlen-2048/52B-train-tokens-from-2.5-passes\"\n",
    "dataset_names = ['c4',\n",
    "                'mc4',\n",
    "                'refined-web',\n",
    "                'wikipedia',\n",
    "                'stack_exchange',\n",
    "                'arxiv',\n",
    "                'peS20',\n",
    "                'markdown-dedup',\n",
    "                'stack-dedup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_PROFILE\"] = \"databricks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to download s3://data-force-one-datasets/mpt-base-data/gpt-neox-20b-seqlen-2048/52B-train-tokens-from-2.5-passes/c4/train/212620/index.json -> /var/folders/9c/c8b828w91kj9bl2_mzsd59lw0000gn/T/tmpzvcijpyg/index.json. Got errors:\n[ClientError('Object s3://data-force-one-datasets/mpt-base-data/gpt-neox-20b-seqlen-2048/52B-train-tokens-from-2.5-passes/c4/train/212620/index.json not found! Either check the bucket path or the bucket permission. If the bucket is a requester pays bucket, then provide the bucket name to the environment variable `MOSAICML_STREAMING_AWS_REQUESTER_PAYS`.'), ClientError('Object s3://data-force-one-datasets/mpt-base-data/gpt-neox-20b-seqlen-2048/52B-train-tokens-from-2.5-passes/c4/train/212620/index.json not found! Either check the bucket path or the bucket permission. If the bucket is a requester pays bucket, then provide the bucket name to the environment variable `MOSAICML_STREAMING_AWS_REQUESTER_PAYS`.'), ClientError('Object s3://data-force-one-datasets/mpt-base-data/gpt-neox-20b-seqlen-2048/52B-train-tokens-from-2.5-passes/c4/train/212620/index.json not found! Either check the bucket path or the bucket permission. If the bucket is a requester pays bucket, then provide the bucket name to the environment variable `MOSAICML_STREAMING_AWS_REQUESTER_PAYS`.')]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/streaming/base/stream.py:199\u001b[0m, in \u001b[0;36mStream._download_file\u001b[0;34m(self, basename)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     download_file(remote, local, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_timeout)\n\u001b[1;32m    200\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:  \u001b[39m# Bubble up file not found error.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/streaming/base/storage/download.py:226\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(remote, local, timeout)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39melif\u001b[39;00m remote\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39ms3://\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 226\u001b[0m     download_from_s3(remote, local, timeout)\n\u001b[1;32m    227\u001b[0m \u001b[39melif\u001b[39;00m remote\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39msftp://\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/streaming/base/storage/download.py:76\u001b[0m, in \u001b[0;36mdownload_from_s3\u001b[0;34m(remote, local, timeout)\u001b[0m\n\u001b[1;32m     72\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject \u001b[39m\u001b[39m{\u001b[39;00mremote\u001b[39m}\u001b[39;00m\u001b[39m not found! Either check the bucket path or the bucket \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m     73\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpermission. If the bucket is a requester pays bucket, then provide the \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m     74\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbucket name to the environment variable \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m     75\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`MOSAICML_STREAMING_AWS_REQUESTER_PAYS`.\u001b[39m\u001b[39m'\u001b[39m,)\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     77\u001b[0m \u001b[39melif\u001b[39;00m e\u001b[39m.\u001b[39mresponse[\u001b[39m'\u001b[39m\u001b[39mError\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m400\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m     \u001b[39m# Public S3 buckets without credentials\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/streaming/base/storage/download.py:66\u001b[0m, in \u001b[0;36mdownload_from_s3\u001b[0;34m(remote, local, timeout)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     _download_file(extra_args\u001b[39m=\u001b[39;49mextra_args)\n\u001b[1;32m     67\u001b[0m \u001b[39mexcept\u001b[39;00m NoCredentialsError:\n\u001b[1;32m     68\u001b[0m     \u001b[39m# Public S3 buckets without credentials\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/streaming/base/storage/download.py:44\u001b[0m, in \u001b[0;36mdownload_from_s3.<locals>._download_file\u001b[0;34m(unsigned, extra_args)\u001b[0m\n\u001b[1;32m     43\u001b[0m s3 \u001b[39m=\u001b[39m boto3\u001b[39m.\u001b[39mclient(\u001b[39m'\u001b[39m\u001b[39ms3\u001b[39m\u001b[39m'\u001b[39m, config\u001b[39m=\u001b[39mconfig)\n\u001b[0;32m---> 44\u001b[0m s3\u001b[39m.\u001b[39;49mdownload_file(obj\u001b[39m.\u001b[39;49mnetloc, obj\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mlstrip(\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m), local, ExtraArgs\u001b[39m=\u001b[39;49mextra_args)\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/boto3/s3/inject.py:190\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mwith\u001b[39;00m S3Transfer(\u001b[39mself\u001b[39m, Config) \u001b[39mas\u001b[39;00m transfer:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m transfer\u001b[39m.\u001b[39;49mdownload_file(\n\u001b[1;32m    191\u001b[0m         bucket\u001b[39m=\u001b[39;49mBucket,\n\u001b[1;32m    192\u001b[0m         key\u001b[39m=\u001b[39;49mKey,\n\u001b[1;32m    193\u001b[0m         filename\u001b[39m=\u001b[39;49mFilename,\n\u001b[1;32m    194\u001b[0m         extra_args\u001b[39m=\u001b[39;49mExtraArgs,\n\u001b[1;32m    195\u001b[0m         callback\u001b[39m=\u001b[39;49mCallback,\n\u001b[1;32m    196\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/boto3/s3/transfer.py:326\u001b[0m, in \u001b[0;36mS3Transfer.download_file\u001b[0;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 326\u001b[0m     future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    327\u001b[0m \u001b[39m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[39m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[39m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[39m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# their own retries.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/s3transfer/futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[39m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[39m# out of this and propagate the exception.\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coordinator\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    104\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/s3transfer/futures.py:266\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m--> 266\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/s3transfer/tasks.py:269\u001b[0m, in \u001b[0;36mSubmissionTask._main\u001b[0;34m(self, transfer_future, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[39m# Call the submit method to start submitting tasks to execute the\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[39m# transfer.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_submit(transfer_future\u001b[39m=\u001b[39;49mtransfer_future, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    270\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    271\u001b[0m     \u001b[39m# If there was an exception raised during the submission of task\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[39m# there is a chance that the final task that signals if a transfer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \n\u001b[1;32m    282\u001b[0m     \u001b[39m# Set the exception, that caused the process to fail.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/s3transfer/download.py:354\u001b[0m, in \u001b[0;36mDownloadSubmissionTask._submit\u001b[0;34m(self, client, config, osutil, request_executor, io_executor, transfer_future, bandwidth_limiter)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m transfer_future\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39msize \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     \u001b[39m# If a size was not provided figure out the size for the\u001b[39;00m\n\u001b[1;32m    353\u001b[0m     \u001b[39m# user.\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mhead_object(\n\u001b[1;32m    355\u001b[0m         Bucket\u001b[39m=\u001b[39;49mtransfer_future\u001b[39m.\u001b[39;49mmeta\u001b[39m.\u001b[39;49mcall_args\u001b[39m.\u001b[39;49mbucket,\n\u001b[1;32m    356\u001b[0m         Key\u001b[39m=\u001b[39;49mtransfer_future\u001b[39m.\u001b[39;49mmeta\u001b[39m.\u001b[39;49mcall_args\u001b[39m.\u001b[39;49mkey,\n\u001b[1;32m    357\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtransfer_future\u001b[39m.\u001b[39;49mmeta\u001b[39m.\u001b[39;49mcall_args\u001b[39m.\u001b[39;49mextra_args,\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    359\u001b[0m     transfer_future\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mprovide_transfer_size(\n\u001b[1;32m    360\u001b[0m         response[\u001b[39m'\u001b[39m\u001b[39mContentLength\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    361\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/botocore/client.py:535\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/botocore/client.py:980\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    979\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 980\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mClientError\u001b[0m: Object s3://data-force-one-datasets/mpt-base-data/gpt-neox-20b-seqlen-2048/52B-train-tokens-from-2.5-passes/c4/train/212620/index.json not found! Either check the bucket path or the bucket permission. If the bucket is a requester pays bucket, then provide the bucket name to the environment variable `MOSAICML_STREAMING_AWS_REQUESTER_PAYS`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m dataset_name \u001b[39min\u001b[39;00m dataset_names:\n\u001b[1;32m      3\u001b[0m     remote \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(remote_base, dataset_name, \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m212620\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     token_counts[dataset_name] \u001b[39m=\u001b[39m StreamingDataset(remote\u001b[39m=\u001b[39;49mremote)\u001b[39m.\u001b[39msize \u001b[39m*\u001b[39m \u001b[39m2048\u001b[39m \u001b[39m/\u001b[39m \u001b[39m1e+9\u001b[39m\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdataset_name\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mtoken_counts[dataset_name]\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTotal: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39msum\u001b[39m(token_counts\u001b[39m.\u001b[39mvalues())\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/streaming/base/dataset.py:264\u001b[0m, in \u001b[0;36mStreamingDataset.__init__\u001b[0;34m(self, streams, remote, local, split, download_retry, download_timeout, validate_hash, keep_zip, keep_raw, samples_per_epoch, predownload, partition_algo, num_canonical_nodes, batch_size, shuffle, shuffle_algo, shuffle_seed, shuffle_block_size)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples_per_stream \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_streams, np\u001b[39m.\u001b[39mint64)\n\u001b[1;32m    263\u001b[0m \u001b[39mfor\u001b[39;00m stream_id, stream \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreams):\n\u001b[0;32m--> 264\u001b[0m     stream_shards \u001b[39m=\u001b[39m stream\u001b[39m.\u001b[39;49mget_shards(world)\n\u001b[1;32m    265\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlen\u001b[39m, stream_shards))\n\u001b[1;32m    266\u001b[0m     stream_per_shard \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [stream_id] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(stream_shards)\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/streaming/base/stream.py:303\u001b[0m, in \u001b[0;36mStream.get_shards\u001b[0;34m(self, world)\u001b[0m\n\u001b[1;32m    301\u001b[0m basename \u001b[39m=\u001b[39m get_index_basename()\n\u001b[1;32m    302\u001b[0m \u001b[39mif\u001b[39;00m world\u001b[39m.\u001b[39mis_local_leader:\n\u001b[0;32m--> 303\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_file(basename)\n\u001b[1;32m    304\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit, basename)  \u001b[39m# pyright: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ai/llm-foundry/env/lib/python3.10/site-packages/streaming/base/stream.py:208\u001b[0m, in \u001b[0;36mStream._download_file\u001b[0;34m(self, basename)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_retry \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(errors):\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    209\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFailed to download \u001b[39m\u001b[39m{\u001b[39;00mremote\u001b[39m}\u001b[39;00m\u001b[39m -> \u001b[39m\u001b[39m{\u001b[39;00mlocal\u001b[39m}\u001b[39;00m\u001b[39m. Got errors:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merrors\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merrors\u001b[39;00m[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    211\u001b[0m \u001b[39mreturn\u001b[39;00m local\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to download s3://data-force-one-datasets/mpt-base-data/gpt-neox-20b-seqlen-2048/52B-train-tokens-from-2.5-passes/c4/train/212620/index.json -> /var/folders/9c/c8b828w91kj9bl2_mzsd59lw0000gn/T/tmpzvcijpyg/index.json. Got errors:\n[ClientError('Object s3://data-force-one-datasets/mpt-base-data/gpt-neox-20b-seqlen-2048/52B-train-tokens-from-2.5-passes/c4/train/212620/index.json not found! Either check the bucket path or the bucket permission. If the bucket is a requester pays bucket, then provide the bucket name to the environment variable `MOSAICML_STREAMING_AWS_REQUESTER_PAYS`.'), ClientError('Object s3://data-force-one-datasets/mpt-base-data/gpt-neox-20b-seqlen-2048/52B-train-tokens-from-2.5-passes/c4/train/212620/index.json not found! Either check the bucket path or the bucket permission. If the bucket is a requester pays bucket, then provide the bucket name to the environment variable `MOSAICML_STREAMING_AWS_REQUESTER_PAYS`.'), ClientError('Object s3://data-force-one-datasets/mpt-base-data/gpt-neox-20b-seqlen-2048/52B-train-tokens-from-2.5-passes/c4/train/212620/index.json not found! Either check the bucket path or the bucket permission. If the bucket is a requester pays bucket, then provide the bucket name to the environment variable `MOSAICML_STREAMING_AWS_REQUESTER_PAYS`.')]"
     ]
    }
   ],
   "source": [
    "token_counts = {}\n",
    "for dataset_name in dataset_names:\n",
    "    remote = os.path.join(remote_base, dataset_name)\n",
    "    token_counts[dataset_name] = StreamingDataset(remote=remote, split=\"train\").size * 2048 / 1e+9\n",
    "    print(f\"{dataset_name}: {token_counts[dataset_name]:.2f}B\")\n",
    "print(f\"Total: {sum(token_counts.values()):.2f}B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
