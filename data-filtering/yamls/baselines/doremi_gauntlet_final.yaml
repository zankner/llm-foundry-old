run_name: doremi-eval
name: doremi-eval
gpu_type: h100_80gb
gpu_num: 16 
cpus: null
platform: null
cluster: r9z1
image: mosaicml/llm-foundry:2.0.1_cu118-latest
partitions: null
optimization_level: null
integrations:
- integration_type: git_repo
  git_repo: zankner/llm-foundry
  git_branch: zack/amortized-selection
  pip_install: -e ".[gpu]"
  ssh_clone: false
- integration_type: pip_packages
  packages:
  - oci-cli
env_variables: []
scheduling: {}
compute:
  cluster: null
  gpu_type: null
metadata: {}
command: '
  cd llm-foundry/scripts

  composer eval/eval.py /mnt/config/parameters.yaml

  '
parameters:
  dist_timeout: 6000
  seed: 3047
  max_seq_len: 2048
  device_eval_batch_size: 8
  precision: amp_bf16
  models:
  - model_name: doremi-final
    load_path: oci://mosaicml-internal-checkpoints/zack/DoReMi/final/final-data-sources-nfs-25K-nfp-1B-domain-weights-nprs-25K-ppr-250M-iter-1-ss-1.0-sm-0.0001-ws-0-seed-17/ckpts/latest-rank0.pt.symlink
  fsdp_config:
    activation_checkpointing: false
    activation_checkpointing_reentrant: false
    activation_cpu_offload: false
    limit_all_gathers: true
    mixed_precision: PURE
    sharding_strategy: FULL_SHARD
    state_dict_type: full
    verbose: false
  icl_tasks: eval/yamls/tasks.yaml
  model_gauntlet: eval/yamls/model_gauntlet.yaml
  run_name: eval-doremi-final
  tokenizer:
    name: EleutherAI/gpt-neox-20b
    kwargs:
      model_max_length: ${max_seq_len}
  model:
    name: mpt_causal_lm
    init_device: meta
    max_seq_len: ${max_seq_len}
    vocab_size: 50432
    expansion_ratio: 4
    no_bias: true
    attn_config:
      alibi: true
      attn_impl: triton
      clip_qkv: 6
      attn_use_sequence_id: true
    d_model: 2048
    n_heads: 16
    n_layers: 24
  loggers:
    wandb:
      project: doremi
      tags:
        - eval
entrypoint: ''
