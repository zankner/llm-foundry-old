run_name: build-ref-loss
platform: # Set in launch script
gpu_type: # Set in launch script
gpu_num: # Set in launch script
image: # Set in launch script
scheduling:
  - resumable: false
integrations:
  - integration_type: git_repo
    git_repo: zankner/llm-foundry
    git_branch: zack/data-filtering
    pip_install: -e .[gpu]
    ssh_clone: true # Should be true if using a private repo
  - integration_type: "pip_packages"
    packages:
      - tiktoken
      - s3fs
      - pandas
env_variables:
  - key: AWS_PROFILE
    value: data-force-one
  - key: NCCL_IB_PCI_RELAXED_ORDERING
    value: 1

command: |
  source /secrets/secrets.env
  export AWS_PROFILE=data-force-one
  cd llm-foundry
  composer data-filtering/build_reference_loss.py --ref-model-size {ref_model_size} --ref-num-tokens {ref_num_tokens} --lr {lr} --ref-global-batch-size {ref_global_batch_size} --final-num-tokens {final_num_tokens} --tokenizer {tokenizer} --dataset {dataset} --available-holdout-tokens {available_holdout_tokens} --seq-len {seq_len} --ref-num-passes {ref_num_passes} --final-num-passes {final_num_passes} --train-seed {seed} --device-batch-size {device_batch_size}
